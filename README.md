# Master Thesis

<center><h2>Electrical Engine Efficiency Prediction Bypassing Finite Element Analysis</h2></center>

## ðŸ“‹ Overview

The aim of the Master Thesis is to train a neural network to learn the parameters of Electric Motors and thus be able to predict its KPIs(key performance indicators). 

We have developed and trained a MLP neural network on the tabular representation of data to predict 2 KPIs. 

The KPIs are 2D and 3D plots on Torque(Mgrenz) curve and Efficiency(ETA) grid.


## ðŸ“· KPIs

| Torque Curve                               | Efficiency Grid                             |
|--------------------------------------------|---------------------------------------------|
| <img src="Manuscript/ReportImages/TorqueCurve.png" alt="Torque Curve" width="370"/> | <img src="Manuscript/ReportImages/EfficiencyGrid.png" alt="Efficiency Grid" width="450"/> |



### âš™ï¸ Dependencies

[![Python Version](https://img.shields.io/badge/python-3.10.14-blue.svg)]()

#### ðŸ–¥ï¸ Operating System

Linux

#### ðŸ Environment

Create conda environment with the dependencies from .yml file as below:

```bash
conda env create -f environment.yml
conda activate thesis
```

When executing the program with python virtual environment

```bash
python -m thesis venv
source ./thesis/bin/activate
pip install -r requirements.txt
```

### ðŸ“ Repo Structure

```python
.
â”œâ”€â”€ src
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ README.md   
â”‚   â”œâ”€â”€ data_preprocessing_tabular.py
â”‚   â”œâ”€â”€ inference.py
â”‚   â”œâ”€â”€ model.py
â”‚   â”œâ”€â”€ scaling.py
â”‚   â”œâ”€â”€ table_creation.py
â”‚   â”œâ”€â”€ training.py
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ GraphModelling
â”‚   â”œâ”€â”€ src
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ README.md 
â”‚   â”‚   â”œâ”€â”€ data_preprocessing_graph.py
â”‚   â”‚   â”œâ”€â”€ dataset_creation.py
â”‚   â”‚   â”œâ”€â”€ model.py
â”‚   â”‚   â”œâ”€â”€ scaling.py
â”‚   â”‚   â”œâ”€â”€ graph_creation.py
â”‚   â”‚   â””â”€â”€ training.py
â”‚   â””â”€â”€ main_graph.ipynb  
â”‚   â””â”€â”€ main_graph.py
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ README.md   
â”‚   â”œâ”€â”€ raw
â”‚   â”œâ”€â”€ DoubleVGraph.json
â”‚   â”œâ”€â”€ EMTabular.json
â”‚   â”œâ”€â”€ Testing
â”‚       â””â”€â”€ raw
â”œâ”€â”€ Intermediate
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ cross_val_splits.npy
â”‚   â”œâ”€â”€ max_mgrenz.pkl
â”‚   â”œâ”€â”€ min_mgrenz.pkl
â”‚   â”œâ”€â”€ x_mean.pkl
â”‚   â””â”€â”€ x_stddev.pkl
â”œâ”€â”€ Manuscript
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ ReportImages
â”‚   â”œâ”€â”€ wandb
â”‚   â”‚   â”œâ”€â”€ loss
â”‚   â”‚   â””â”€â”€ score
â”‚   â”œâ”€â”€ Report.pdf
â”‚   â””â”€â”€ Report.tex
â”œâ”€â”€ Presentations
â”‚    â””â”€â”€ README.md
â”œâ”€â”€ .gitignore
â”œâ”€â”€ environment.yaml
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ data_preprocessing.py
â”œâ”€â”€ main.ipynb
â”œâ”€â”€ main_train.py
â””â”€â”€ .env.local
```

## ðŸ“– Usage

### ðŸ”‘ Secrets (.env.local)
  
WANDB_API_KEY=API KEY

### ðŸ—ƒï¸ Data Preprocessing

Store the files for training within folder data -> raw

Run the below command for generating preprocessed tabular data

```bash
python data_preprocessing.py
```

The jupyter notebook main.ipynb hosts the code for the remaining  sections

### ðŸ“Š Data Exploration

Data explorations based on tabular summary statistics and Standard Deviation

### ðŸ‹ï¸ Training

To run training separately for already processed files

```bash
python main_train.py
```

To run training for new files and if you want to supply the maximum and minimum torque instead of script finding from whole dataset.
Example values maximum and minimum torque 283 and 55 then run

```bash
python main_train.py --max_torque 283 --min_torque 55
```

### ðŸ” Inference

There are options to either :

1. Generate model predictions of new files, store them in folder data -> Testing -> raw and run the cell highlighted in the main.ipynb notebook

2. Generate model predictions of test dataset separated before training, in that case simply skip the cell mentioned in Step 1.

### ðŸ“ˆ Evaluation

Evaluation of Predictions are based on RMSE, Deviation of Folds, Difference Overlaps, Percentage Differences